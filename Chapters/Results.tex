\chapter{Results}
\label{ch:Results}

In this chapter, we outline our investigations into the effects of small $n$ on the Multiple Initiator Model.
Using the MIM simulator described in Ch.~\ref{Methods}, we performed four major investigations.

Our preliminary investigation was a single-origin comparison between the analytical MIM and the MIM Simulator.
We defined a parameter that measures the difference between the replicated fraction from simulation and from the MIM.
In Sec.~\ref{subsec:earlywork}, our so-called ``difference parameter'' shows that small $n$ does create a disagreement between the analytical MIM and the MIM simulator proportional to $n^-1$.
The presence of this error and its large tail motivated further study into the effect of small $n$ on the MIM.

In our second investigation, our goal was to develop a new metric for measuring the error in the MIM at low $n$.
The difference parameter does not scale well.
Section~\ref{subsec:BiasedFits} outlines the new method, which consists of simulating the replicated fraction for a single origin of fixed $n$, followed by using the MIM to find the value of $n$ that best fits the simulated data.
The results of this investigation show that our first approach, while qualitatively in agreement, overestimates the difference between the MIM and the simulation.

Third, we progressed to simulating and fitting the more complex Chromosome I.
For this investigation, we fit parameters with the MIM to data from DNA sequencing~\ref{StochasticTermination}.
we fit two sets of parameters, and by fixing $t_{1/2}$ as high and low, we forced the MIM to produce small and high $n$ respectively.
Using the parameters from the fits, we then simulated the replication of Chromosome I.
By calculating the root-mean-squared difference between simulated data and experimental data we showed that the two simulations are indistinguishable from each other.
Further, analysis of the fit parameters shows that the small-$n$ values are proportional to the large-$n$ values.

The surprising results from our third investigation motivated additional work that we use to explain why the MIM is inaccurate for a single origin but produces good chromosome-wide results.
We expanded our single-origin analysis to a genome with two origins and show that two origins interact to reduce the inaccuracy in the MIM.
We present a hypothesis that explains why the MIM works well in the presence of many origins.

	\section{Single-Origin Investigations}
	\label{sec:SingleOrigin}
	
	Our early work consisted of single-origin simulations to motivate further study.
	Early in 2014, we received the results discussed in Sec.~\ref{sec:ExperimentsMIM} from N.~Rhind's lab~\cite{Rhind}.
	As mentioned, these results called into question the assumption that $n$ is large enough to ignore variations in $N$.
	Our first goal, therefore, was to discover whether simulations of small $n$ agreed with the MIM predictions for small $n$ or not.
	In this naive investigation, discussed further below, we developed ``the difference parameter,'' a metric to measure the difference between the simulated and predicted $f(x,t,n)$ of a single origin with average $n$ initiators.
	The investigation showed the difference parameter decreased as $n^{-1}$ and motivated the deeper research presented in this thesis.
	
	The single-origin investigations that followed our preliminary work consisted of simulating $f(n)$ and fitting the MIM parameters to the result.
	Thus our metric charged from the difference parameter to a comparison between the simulated $n_\text{sim}$ and the fitted $n_\text{fit}$.
	With these investigations, we refined the simulation program to run more efficiently, and to create data similar to that measured in sequencing experiments.
	We show that our new metric reveals a qualitatively similar behaviour for the MIM; the difference between $n_\text{sim}$ and  $n_\text{fit}$ goes approximately as $n^{-1/2}$.
	We attribute the change in the rate to the change in how the metric is defined.
		
	\begin{figure}[tbh!]
		\begin{center}
			\includegraphics[width=\textwidth]{Images/DifferenceParameterGraph.pdf}
		\end{center}
			\caption[Difference Parameter]{\label{fig:DifferenceParameter} Schematic of the difference parameter calculations.
				Coloured lines represent the difference parameter for different values of $n$.
				Triangles show the parameter values in the corresponding inset graphs.
				\textbf{A} Replication fraction simulation and theory curves for $n=10$; $DP=0.037$.
				\textbf{B} Replication fraction simulation and theory curves for $n=5$; $DP = 0.062$.
				\textbf{C} Replication fraction simulation and theory curves for $n=1$; $DP = 0.264$.
				Also illustrated in \textbf{C} is the value $\Delta P(x)$ at the peak.
				Note that $\Delta P(x)$ is defined over the entire domain.
				}
	\end{figure}
	
	
		\subsection{The Difference Parameter}
		\label{subsec:earlywork}
		
		When this project started, we performed a quick investigation into the difference between $f_\text{sim}(n)$ and $f_\text{MIM}(n)$ for a single origin.
		To generate $f_\text{sim}(n)$, the MIM simulator calculated the average replicated fraction for about $10^6$ sequences, producing data with very little statistical error.
		The global parameters used for the simulation were set equal to those measured previously by fitting the MIM to microarray measurements of budding yeast~\cite{ScottsPaper}.
		The difference parameter was then defined as
		\begin{equation} \label{DifferenceParameter}
			DP = \max_{x} {\frac {\Delta P(x)} {P}} \text{ ,}
		\end{equation}
		where $\Delta P(x)$ is the difference between $f_\text{sim}(n)$ and $f_\text{MIM}(n)$ (see Fig.~\ref{fig:DifferenceParameter}), and $P$ is the peak value of $f_\text{MIM}(n)$.
		
		Figure~\ref{fig:DifferenceParameter} shows the analysis process of the difference parameter for a single origin.
		First, $f_\text{sim}(n)$ and $f_\text{MIM}(n)$ were calculated over several time steps and $n$ ranging from one to 128, example replicated fractions are shown in the insets of Fig.~\ref{fig:DifferenceParameter}.
		From these data, we calculated $DP(n,t)$, shown the main image in Fig.~\ref{fig:DifferenceParameter}.
		Note the value for $DP$ ``saturates'' as $t$ increases, we call this value the ``saturated difference parameter.''
		Figure~\ref{fig:SaturatedDifferenceParameter} shows the saturated difference parameter as a function of $n$\footnote{
		The reader may notice a change in the $n$ values displayed in the graphics. Figure~\ref{fig:DifferenceParameter} is illustrative and contains old data; accurate, but not useful.
		After producing that graph we used a slightly different set of parameters in the simulation and changed the range of $n$ simulated when producing Fig.~\ref{fig:SaturatedDifferenceParameter}}.
		This initial investigation showed the saturated difference parameter decreases as $n^{-1}$.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=0.8\textwidth]{Images/SaturatedDifferenceParameterGraph.pdf}
			\end{center}
				\caption[Saturated Difference Parameter]{\label{fig:SaturatedDifferenceParameter} Saturated difference parameter vs. $n$.
				The large uncertainty in low $n$ arises because the time-steps not going far enough to accurately measure the saturated difference parameter.
				The line is proportional to $n^{-1}$ ($\text{[Saturated Difference Parameter]} \approx \frac{0.3}{n}$).
				}
		\end{figure}
		
		From our initial investigation, we concluded that the difference parameter grows quickly with decreasing $n$.
		Therefore, we suspect that the MIM will not produce accurate results in the case that $n$ is small.
		These results motivated further research into the effect of small $n$ on the MIM.
		
		
		\subsection{Biased Fits}
		\label{subsec:BiasedFits}
		
		The definition of the difference parameter does not scale to more than one origin.
		The saturated difference parameter is only measurable when the theory curve has a peak value near one, therefore near-neighbour origins will interfere with each other.
		Additionally, the difference parameter is defined as a single value for the whole simulated genome, therefore we cannot infer anything about more than one origin.
		Thus, we developed a second investigation that measures how the parameters fitted with the MIM to a simulation of small $n$ may be biased.
		
		The process of this investigation was to calculate $f_\text{sim}(n)$ and to follow that by fitting the parameters of the MIM to the result.
		Thus, we have two parameters, $n_\text{sim}$ and $n_\text{fit}$, where $n_\text{sim}$ is the value for $n$ input to the simulation, and $n_\text{MIM}$ is the value for $n$ that results from the MIM fit.
		Initially, we performed these measurements using simulations of large populations sets of sequences (about $10^6$ and more 100 kb sequences).
		However, even using a C++ module to increase performance, these simulations were slow and were far more accurate than the current experimental standard (Sec.~\ref{sec:Noise}).
		Therefore, we limited our simulations as described in the previous chapter; in this way we simulated data comparable to those generated experimentally.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=0.47\textwidth]{Images/LargePopBias.pdf}
			\end{center}
			\caption[Bias in MIM fit on Large-Population Simulations]{\label{fig:LargePopulation} Scatter plot of $n_\text{sim}$ vs. $n_\text{fit}$ for simulations of a large population.
			Red circles show the data, dashed line shows unity.
			There is a large bias for low $n_\text{sim}$ which decreases as $n_\text{sim}$ grows.
			}
		\end{figure}
		
		Figure~\ref{fig:LargePopPopulation} shows the preliminary results from our biased fit investigation on large-population simulations.
		The graph is a scatter plot of $n_\text{sim}$ vs. $n_\text{MIM}$, the dashed line shows unity.
		As we expected, the biased is relatively large for low $n_\text{sim}$, but decreases as $n_\text{sim}$ grows.
		Before this line of analysis went any deeper, however, we restructured the program to create noisy data.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=0.8\textwidth]{Images/NoisyBias.pdf}
			\end{center}
				\caption[Bias in MIM fit on Noisy Data]{\label{fig:NoisyBias} Scatter plot of $n_\text{sim}$ vs. $n_\text{fit}$ for simulations of noisy data.
				Red dots show data from 50 simulations at each value $n_\text{sim}$.
				Blue circles with error bars show the mean and standard deviation of the mean.
				Dashed line shows unity.
				The bias for low $n_\text{sim}$ decreases with increasing $n_\text{sim}$.
				\textbf{Inset} Scatter plot of the normalized difference ($[n_\text{sim} - n_\text{fit}]/n_\text{sim}$) vs. $n_\text{sim}$.
				$\text{[Dashed line]} = 0.315/\sqrt{n_\text{sim}}$.
				}
		\end{figure}
		
		In Sec.~\ref{Sec:Noise} we outlined the process used to generate noisy data.
		Figure~\ref{fig:NoisyBias} shows the result of our analysis of noisy simulated data.
		Again, we used the MIM Simulator to generate $f_\text{sim}(n_\text{sim})$ and using a built-in IGOR Pro function, we fit the parameters of the MIM to that data.
		Figure~\ref{fig:NoisyBias} is a scatter plot of $n_{sim}$ vs. the resulting $n_\text{fit}$.
		In this case, because of the increased noise in the simulated data, we performed this procedure fifty times per $n_\text{sim}$ value (red dots).
		The blue data show the mean and standard deviation of the mean for each value of $n_\text{sim}$.
		Here, again, we see that the bias is largest for small $n_\text{sim}$, and decreases $n_\text{sim}$ grows.
		In the inset to Fig.~\ref{fig:NoisyBias} we show the relative difference normalized by $n_\text{sim}$ (i.e. $[n_\text{sim} - n_\text{fit}]/n_\text{sim}$).
		The dashed line shows $0.315/\sqrt{n_\text{sim}}$, but that trend is presented only for comparison with the difference parameter; there doesn't seem to be a simple fit.
		
		The data shown in Fig.~\ref{fig:NoisyBias}, which comes from fitting the MIM to artificially noisy simulated data, shows the behaviour we expect:
		The MIM works poorly when $n$ is small, and better with increasing $n$.
		Therefore, we concluded that the MIM simulator is producing good data, that is comparable to both experimental data and the analytical MIM.
		Additionally, these results motivated exploring the same process on multiple origins.
		
		
	\section{Simulations of Chromosome I}
	\label{sec:ChromosomeI}
	
	Our results from single-origin simulations seem to indicate that the MIM does not perform well in the small-$n$ regime, but multiple origins work together to reduce that effect.
	Following our single-origin investigation, we simulated the replicated fraction of Chromosome I of budding yeast.
	For this investigation, we used the same simulation method as described for the noisy single-origin analysis, except that the genome size and origin parameters were chosen to represent Chromosome I.
	The origin parameters were set by fitting the MIM to the replicated fraction for wild-type budding yeast reported by Hawkins~\emph{et al.}~\cite{StochasticTermination}.
	To test the effect of small $n$, the fitted parameter $t_{1/2}$ was fixed at a high value (90 minutes) to produce high values for $n$, and it was fixed at a low value (40 minutes) to produce low values for $n$.
	To be sure that any effects we observed were due only to the fitted values of $n$, the origin positions were held constant for the two fits.
	The resulting values for $n$ at each origin can be seen in table~\ref{tab:LargeAndSmallN}.
	
	\begin{table}
		\begin{center}
			\begin{tabular}{| r | c | c | c | c | c | c |}	
				\hline
				Position (kb)	&	38.3	&	72.6	&	124.2	&	155.6	&	174	&	216	\\	\hline
				Small $n$	&	1.65	&	1.93	&	2.3	&	2.5	&	5.7	&	1.5	\\
				Large $n$	&	10.2	&	12	&	14	&	16	&	36	&	9	\\	\hline
			\end{tabular}
		\end{center}
		
		\caption[High and low $n$ fit values for Chromosome I]{\label{tab:LargeAndSmallN}
			High and low fitted values for $n$ on Chromosome I.
			Top row shows the fixed positions of the six fitted origins.
			Center row shows the values of $n$ when $t_{1/2}=40$.
			Bottom row shows $n$ from a fit with $t_{1/2}=90$
		}
	\end{table}
	
	We simulated
	







































