\chapter{Methods}
\label{ch:Methods}

In this chapter, we outline the tools we used in our investigation of the impact of variability in the initiation factor on the MIM.
The primary tool that we developed for our investigation is the MIM simulator, a Monte Carlo program that simulates DNA replication.
A great deal of effort went into the details of the simulation program to ensure it efficiently produces meaningful results:
We ensured the randomly generated numbers were distributed properly.
We adopted the phantom-nuclei algorithm, an efficient way to simulate the replicated fraction~\cite{KJMA1}.
We used multiple programming languages to increase performance.
We simulated measurements consistent with current experimental results~\cite{StochasticTermination}.

Except when noted, all computations were performed in IGOR Pro Version 6.3.6.4.


	\section{The MIM Simulator}
	\label{sec:MIMSimulator}
	
	The MIM simulator takes as inputs a set of parameters nearly identical to those defined by the MIM.
	There are four global inputs: the elapsed time since the start of S phase $t_\text{sim}$, the speed of replicative forks $v$, the median firing time $t_{1/2}$, and $r$, which defines the width of the cumulative firing time distribution.
	There are also two local parameters per origin: the position $x_i$ and the average number of initiators $n_i$.
	This set of parameters is not identical to those outlined in Sec.~\ref{sec:MIM} because, as we will describe in Sec.~\ref{sec:Noise}, noise was not treated the same way.
	The simulator uses these parameters to generate the replicated fraction, $f(x,t=t_\text{sim})$, over the entire genome.
	The simulation does this over several sets of parameters for which only $t_\text{sim}$ changes by steps of 5 minutes, thereby efficiently creating data comparable to those from sequencing experiments.
	
	The MIM simulator has three modules (see Fig.~\ref{fig:ProgramStructure}):
	The preparation module sets the randomly distributed parameters.
	The phantom-nuclei module uses those parameters to calculate $f(x,t=t_\text{sim})$.
	The housekeeping module tracks progress, calls the preparation and phantom-nuclei modules, and analyzes the results.
	Note that while the preparation and the phantom-nuclei modules both simulate only a single cell at a time, the housekeeping module loops over many cells to find the average behaviour of a population.
	These three modules will be discussed in more detail below.
		
	\begin{figure}[tbh!]
		\begin{center}
			\includegraphics[width=.8\textwidth]{Images/ProgramStructure.pdf}
		\end{center}
			\caption[MIM Simulator Program Structure]{\label{fig:ProgramStructure} 
				Flow chart illustrating the MIM simulator structure.
				The program contains three modules: 
				The housekeeping module loops over every cell in the population being simulated, calls the preparation and phantom nuclei modules, adds noise to the results and performs analysis.
				The preparation module generates two sets of random data, the number of initiators at each origin and the firing times of each initiator.
				The phantom-nuclei module pre-processes the data passed to it, and calculates the replicated fraction for each time step using the phantom nuclei algorithm, which is broken into three steps.
			}
	\end{figure}
	
	
		\subsection{The Preparation Module}
		\label{subsec:PrepModule}
		
		The preparation module is a Monte Carlo program, one whose output depends on random numbers~\cite{CompPhys}.
		For the preparation module of the MIM simulator,  we need two sets of random numbers:
		First, the program requires a set of absolute numbers of initiators, $\{N_i\}$, for all origins $i$.
		Second, the program requires a set of firing times, $\{t_{i,j}\}$, for each initiator $j$ loaded at each origin $i$.
		For both sets, we took care to ensure that the generated values were properly distributed to match MIM theory (Sec.~\ref{sec:MIM}).
		The preparation module is analogous to the licensing process undertaken in the G1 phase of the cell cycle (Sec.~\ref{subsec:G1Phase}).
			
		The first task of the preparation module is to randomly generate $\{N_i\}$, the set of absolute numbers of initiators at all origins $i$ for the cell being simulated.
		Thus, the first choice we made in creating the simulator was how the values for $N_i$ should be distributed, given their average $n_i$.
		In Sec.~\ref{subsec:MIMBasics}, we mentioned that a simple hypothesis is that initiators are loaded onto an origin as a Poisson process; if this is the case, the number of initiators should be Poisson distributed.
		This simple model, which assumes initiators are loaded at a constant rate and loading events are not correlated, is easily implemented using built-in IGOR functions.
		However, we are unaware of any experiments that have measured the distribution of the number of initiators over different cell cycles.
		
		In discussion with collaborators, another hypothetical distribution was considered.
		Several studies have shown that Histone activity\footnote{
		Histones are large, octameric proteins that play a role in organizing DNA into its three-dimensional structure in the cell~\cite{MolecularCellBiology}.}
		is correlated with origin locations~\cite{Histone,Histone2,Histone3}; origins tend to be in open, easily accessible regions of the DNA
		We hypothesis that the accessibility also affects the rate of initiator loading, and that the first initiator at an origin may load much faster than additional initiators.
		One way to implement qualitatively this idea would be to enforce a minimum probability for loading at least one MCM2-7 pair.
		(In an extreme case, this probability would be one.)
		
		We chose to use the Poisson distribution for setting the number of initiators at an origin for two reasons:
		First, without experimental evidence to motivate the selection of a complex model, the simple model is preferred.
		Second, since we are testing the efficacy of the MIM, which assumes constant $n$, the Poisson distribution represents a worst-case scenario:
		It includes the possibility of loading zero initiators, and having zero initiators leads to the largest perturbation from the assumption made in the MIM.
		Therefore, the preparation module selects the number of initiators at origin $i$ from a Poisson distribution defined by the average $n_i$.
		
		The second task of the preparation module is to assign a firing time to each initiator on the genome.
		This is different from assigning a firing time to each origin: If there are $k$ origins, then the number of initiators is given by $\sum\nolimits_{i=0}^k N_i = K$.
		Therefore, $K$ randomly generated firing times are required.
		The MIM dictates the desired firing time distribution of an initiator, which we derive from the cumulative firing time probability shown in Eq.~\ref{eq:CPDInitiator} (and again in Eq.~\ref{eq:CPDInitiator2}).
		\begin{equation} \label{eq:CPDInitiator2}
			\Phi_0(t) = \frac{1}{1+\left(\frac{t^*_{1/2}}{t}\right)^{r^*}}\text{ ,}
		\end{equation}
		where $t^*_{1/2}$ and $r^*$ are global parameters defining, for a single initiator, the median firing time and the spread in firing times respectively. 
		Recognizing that $\Phi_0$ goes from zero (when $t=0$), to one (when $t \rightarrow \infty$), we can use inverse transform sampling~\cite{NumRec} to randomly generate firing times that reproduce the desired cumulative firing time probability.
		If we generate $u$, a uniformly distributed number between zero and one we can transform that to be distributed as desired with
		\begin{equation}
			F(u) = \frac{t^*_{1/2}}{\left(\frac{1}{u}-1\right)^\frac{1}{r^*}} \text{ ,}
		\end{equation}
		where $F(u)$ is the firing time.
		This will produce random numbers that exhibit a cumulative probability distribution given by Eq.~\ref{eq:CPDInitiator2}.
		A histogram of $10^5$ samples from the transformation coincided satisfactorily with the cumulative fire-time distribution, implying that the method is sound.
		After all $K$ firing times are generated, the time of the first-to-fire initiator at each origin is kept because each origin can only fire once; thus, the firing time of the origin $i$ is given by the firing time of the earliest initiator $\text{min}\{t_j\}_i$.
		
		
		\subsection{The Phantom-Nuclei module}
		\label{subsec:PhanNuc}
		
		Based on work done by S.~Jun~\emph{et~al.}, the phantom-nuclei algorithm we used in the simulation is a powerful tool for calculating replicative data from a set of parameters describing the origins of replication in the KJMA formalism~\cite{KJMA1}.
		Figure~\ref{fig:phantom} illustrates the key features of the phantom-nuclei method.
		There are three major steps in our phantom nuclei module: pre-processing the parameters, simulating replication, and compiling the replicated fraction.
		In taking these three steps, the phantom nuclei module quickly calculates the regions on the genome of a single cell which have been replicated.
		These steps have been separated for the sake of clarity; however, there is some overlap between them in our implementation to increase performance.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=\textwidth]{Images/PhantomNuclei.png}
			\end{center}
				\caption[Schematic of the Phantom Nuclei Algorithm]{\label{fig:phantom} Schematic of the Phantom Nuclei algorithm.
				Only the active origins (Black circles) are considered during simulations.
				Open circles correspond to passively replicated origins (``phantom'' nuclei).
				The algorithm outputs the replicated fraction, which is one in replicated regions (ellipses at top) or zero in unreplicated regions (black line at top).
				}
		\end{figure}
			
		The strength of the phantom nuclei algorithm is that it pre-processes the origin data it receives.
		To reduce the amount of work needed to fully simulate the replication process, the program removes origins that are passively replicated (``phantom'' nuclei) from the simulation.
		As we mentioned above, we designed the simulator to loop through many values of $t_\text{sim}$.
		The algorithm starts by calculating the state of replication at the highest value for $t_\text{sim}$, $t_\text{sim}^\text{(max)}$.
		We start at $t_\text{sim}^\text{(max)}$ because that is when every meaningful event will have occurred: origins have fired or not, and every passively replicated origin can be identified.
		
		When pre-processing, the program calculates the positions $\{x_i^\text{(L)}\}$ of the left forks and $\{x_i^\text{(R)}\}$ of the right forks originating from all origins $i$.
		Calculating these positions is done via simple kinematics:
		\begin{equation} \label{eq:findforks}
			x_i^{\binom{\text{R}}{\text{L}}} = x_i \pm v \times \left( t_\text{sim} - t_i\right) \text{ ,}
		\end{equation}
		where the right fork is given by the sum and the left fork by the difference, and where the bracketed term calculates the time since the origin fired.
		As a part of pre-processing, any origins for which $t_i > t_\text{sim}^\text{(max)}$ are immediately removed from the simulation, as they will not contribute to the replicated fraction.
		Once the algorithm calculates the set of fork locations, the forks from each pair of neighbouring origins are analyzed to determine which origins are passively replicated.
		Any phantom nuclei are removed from the simulation (open circles in Fig.~\ref{fig:phantom}).
		Pre-processing is finished when only active origins (black circles in Fig.~\ref{fig:phantom}) are left in the simulation.
		Pre-processing is computationally expensive, but for complex genomes will dramatically decrease the calculations needed for the second step, and the number of calculations needed for this process on simple genomes is small.
		
		The second step of the phantom nuclei algorithm is the largest and is used at every time step.
		During the simulation step, the algorithm performs three major calculations:
		First, it selects which origins will fire by comparing their firing times to the current value of $t_\text{sim}$; only origins with $t_i < t_\text{sim}$ will fire.
		Second, using Eq.~\ref{eq:findforks}, the algorithm calculates two sets of fork positions ($\{x_i^\text{(L)}\}$ and $\{x_i^\text{(R)}\}$) from the origins selected in the first step.
		These two sets of fork data are used to define replicated regions on the genome.
		Third, it analyzes the replicated regions defined by the two sets of fork data, and identifies where replicated regions overlap (i.e., coalescence has occurred).
		Any overlapping regions are combined.
		This step is analogous to the S phase of the cell cycle, including initiation (selecting cells that fire before $t_\text{sim}$), elongation (calculating fork positions), and coalescence (combining overlapping regions), as described in Sec.~\ref{subsec:SPhase}.
		
		Immediately after any overlapping replicated regions are coalesced, the algorithm compiles the replicated fraction.
		Therefore, the replicated fraction is compiled at every time step in the simulation.
		To compile the replicated fraction, the algorithm simply loops through the replicated regions defined by $\{x_i^\text{(L)}\}$ and $\{x_i^\text{(R)}\}$ and sets the replicated fraction for the cell to one inside those regions and zero outside.
		Although this process may sound straightforward, we were unable to do it without nested loops that significantly slowed the simulation process.
		For this reason, this step was written both in IGOR and in C++.
		When we simulated large data sets early in our work (Sec.~\ref{subsec:earlywork}), we called the C++ function as an external program.
		Using this external function gave an 8-fold increase in performance.
		
		
		\subsection{The Housekeeping Module}
		\label{subsec:Housing}
		
		The simulation described above calculates the replicated fraction on the entire genome of a single cell.
		However, we are investigating sequencing data that are acquired by averaging over a large population.
		Therefore, the housekeeping module is designed to loop over a population calling the preparation and phantom nuclei modules for each cell.
		The resulting data are then averaged.
		
		In addition, the housekeeping module can analyze and alter the simulated replicated fraction $f_\text{sim}$.
		In our research, we fit the MIM parameters to $f_\text{sim}$; we added Gaussian noise to reflect current experimental measurements; and we calculated the difference between $f_\text{sim}$ and experimentally measured $f$.
		We discuss these procedures and their results in Ch.~\ref{ch:Results}.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=\textwidth]{Images/SimulatedDataExamples.pdf}
			\end{center}
				\caption[Simulated Replicated Fraction for Chromosome IV]{\label{fig:SimulatedExample}
					Example output of Chromosome IV from the MIM simulator.
					x-axis is the position in the genome.
					y-axis is the replicated fraction.\\
					\textbf{A.} Data averaged over 100 cells, no artificial noise.\\
					\textbf{B.} Data averaged over 100 cells, Gaussian noise added according to the procedure outlined in Sec.~\ref{subsec:AddingNoise}.
					Parameters for the simulation were taken from~\cite{ScottsPaper} supplementary data.
				}
		\end{figure}	
		
		
		\subsection{Qualities of the MIM Simulator}
		\label{subsec:QualitiesofMIMSimulator}
		
		The MIM simulator is a powerful tool for generating the replicated fraction of a population of cells with known $\{n_i\}$.
		The Monte Carlo process used in the MIM Simulator calculates the replicated fraction as the average of a population of cells.
		Therefore, the larger the population, the better the averaging and the more confident we are in the data.
		It may seem simple to use the MIM simulator instead of the analytical MIM shown in Sec.~\ref{sec:MIM}.
		However, simulating the replicated fraction to the accuracy needed for a fit takes many thousands of single-cell measurements to average over, and this is computationally expensive.
		By contrast, a single calculation with the analytical MIM will produce the desired fit function.
		Thus, the MIM simulator is not a good replacement for the analytical MIM; rather, it is a too we use to measure the efficacy of the analytical MIM in the small-$n$ regime.
		
		One of the strengths of our program is its modular structure: It is simple to change the probability distribution of $\{N_i\}$ (currently Poisson distributed) or $\{t_j\}_i$ (currently distributed as described above).
		Additionally, doing new analysis is simply a matter of creating a new function that the housekeeping module can call.
		
		Figure~\ref{fig:SimulatedExample} shows two examples of the replicated fraction of Chromosome IV\footnote{
		Figure~\ref{fig:ReplicatedFractionExample} shows the replicated fraction of the same chromosome measured with DNA sequencing~\cite{StochasticTermination}.}
		generated by the MIM Simulator.
		Both simulations were over a population of 100 cells.
		Figure~\ref{fig:SimulatedExample}A shows data output from the program as described so far.
		Below, we describe how and why we generated the noisy data presented in Fig.~\ref{fig:SimulatedExample}B
		
		
	\section{Analyzing Noise in the Data}
	\label{sec:Noise}
	
	For our initial investigations, we chose to do simulations of many simple artificial cells.
	However, as we discuss in Sec.~\ref{subsec:BiasedFits}, this was not a good choice because this method does not scale well to complex cells.
	Because of this problem, we created simulations that were limited in population size and accuracy to reflect current experimental standards.
	We expected that limiting the population size would increase the noise enough to make a good comparison with experiment.
	However, as we show below, generating noisy data was not as simple as limiting our population size.
	
	
		\subsection{Estimating Experimental Noise}
		\label{subsec:SequencingNoise}
		
		Here, we analyze data from a sequencing experiment investigating the replicated fraction of budding yeast performed by Hawkins~\emph{et~al.} in 2013~\cite{StochasticTermination}.
		In their experiment, Hawkins~\emph{et~al.} used DNA sequencing to calculate the replicated fraction of two strains of budding yeast: wild-type budding yeast and a mutant with three origins of replication removed.
		Figure~\ref{fig:ReplicatedFractionExample} shows their results for Chromosome IV of the wild-type genome.
		Notice that the noise in the experiment leads to replication fraction estimates that lie outside the possible range between zero and one.
		Our goal was to create simulated replicated fraction data that closely resembles data from sequencing experiments.
		To do this, we need to include noise in our data commensurate with that seen experimentally and must therefore estimate experimental noise.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=\textwidth]{Images/WTvsMutDifference.pdf}
			\end{center}
				\caption[Estimating Experimental Noise: Mean Point-By-Point Difference]{\label{fig:MeanDifference} Mean point-by-point difference between wild-type and mutant replicated fractions for each chromosome at each time step.
					Each set of axis is for a different time after the start of S phase (labeled).
					y-axis shows the mean difference.
					x-axis is the chromosome label.
					Note that no data are shown for Chromosomes VI, VII, and X, as they were not analyzed due to their mutations.
					Data derived from~\cite{StochasticTermination} supplementary data.
				}
		\end{figure}
		
		Following the process used by Yang~\emph{et al.}~(\cite{ScottsPaper} supplementary material), we analyzed the experimental data to estimate the uncertainty in the measured replicated fraction.
		Ideally, we would estimate the noise distribution for each data point by analyzing data from an experiment that has been repeated many times.
		Unfortunately, Hawkins~\emph{et~al.} did not publish any repetitions of their data set.
		Therefore, we worked with two measurements we assume to be in close agreement: the wild-type budding yeast and the mutant budding yeast measurements reported in~\cite{StochasticTemination}.
		With the mutation only removing three origins, we assumed that the replication profiles between the wild-type and mutant measurements would be the same except on the chromosomes with missing origins (Chromosomes VI, VII, and X).
		Thus, we compared the remaining 13 of the total 16 budding yeast chromosomes.
		To estimate the distribution of fluctuations, we considered how the differences between the experiments, calculated point-by-point, were distributed.
		Figure~\ref{fig:MeanDifference} shows the mean difference for each chromosome ($x$-axis) at each time step (separate axis, labeled).
		Since the differences vary in time, they are analyzed at each time step separately.
		Within each time point the fluctuations are much more stable, except for a downward trend in Chromosome III.
		Thus, in addition to the three chromosomes that were mutated, Chromosome III was removed from our analysis.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=\textwidth]{Images/WTvsMutHistograms.pdf}
			\end{center}
				\caption[Estimating Experimental Noise: Point-By-Point Difference Distributions]{\label{fig:HistDifference} Histograms of the point-by-point difference between wild-type and mutant data and Gaussian fits.
					Each set of axis is for a different time after the start of S phase (labeled).
					y-axis shows the normalized distribution.
					x-axis shows difference.
					Grey circles are calculated from experiment~\cite{StochasticTermination}.
					Black lines show the best Gaussian fit
					Note that no data are shown for Chromosomes III, VI, VII, and X.
					Data derived from supplementary data from~\cite{StochasticTermination}.
				}
		\end{figure}
		
		After removing the data from the four chromosomes mentioned, we compiled histograms for the six time steps measured.
		These histograms (shown in Fig.~\ref{fig:HistDifference}) estimate the probability distribution between the two noisy measurements.
		To properly duplicate the noise of a single experiment, we need the distribution of a single noisy measurement.
		From elementary properties of the variance, two independent random variables $A$ and $B$ have $\text{Var}[A-B] = \text{Var}[A] + \text{Var}[B]$.
		We assume that the two measurements are equally noisy, which implies that the standard deviations of the differences are $\sqrt{2}$ times larger than the standard deviation of a single measurement.
		Our estimates of the noise are shown as open circles in Fig.~\ref{fig:Noise}.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=.8\textwidth]{Images/SigmaEstimate.pdf}
			\end{center}
				\caption[Scatter Plot of Estimated Simulation and Experimental Noise]{\label{fig:Noise} 
					Scatter plot of estimated $\sigma$ vs time since the start of S phase for experimental data and simulation data.
					Open circles show experimental estimates.
					Black circles show simulation estimates.
					Crosses show calculated values for $\sigma_\text{add}$ (Eq.~\ref{eq:AddingNoise})
					Squares show estimates from sequencing simulations.
					Dots show estimates from simulations with added Gaussian noise.
				}
		\end{figure}
		
		There are three features of the histograms in Fig.~\ref{fig:HistDifference} that should be discussed.
		First, unlike the microarray data that Yang~\emph{et al.} analyzed, the histograms extracted from sequencing data are Gaussian distributed.
		This implies that the data sequencing experiments are better suited to analysis with the MIM, since the MIM approach assumes Gaussian-distributed noise~\cite{ScottsPaper}.
		Second, the standard deviation evolves as time progresses.
		This is expected: Early in the replication program and late in the replication program, many of the cells will be mostly unreplicated and mostly replicated  respectively.
		Therefore, we expect that the noise will be diminished at early time and late time.
		Third, the mean of the Gaussian fits evolve dramatically as time progresses.
		We believe this is due to a global systematic error in the data, potentially the reported time since the start of S phase, or a possible global effect of the mutation that removes origins from Chromosomes VI, VII, and X.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=.8\textwidth]{Images/Correlation.pdf}
			\end{center}
				\caption[Autocorrelation of Experiment and Simulations]{\label{fig:correlation}
					Autocorrelation of experimental data and data from three simulations of the full budding yeast genome.
					\textbf{A.} Autocorrelation of simulated data of a population of 100 cells.
					\textbf{B.} Same as \textbf{A}, with artificial noise added as described in Sec.~\ref{subsec:AddingNoise}.
					\textbf{C.} Autocorrelation of experimental data  over the full genome (calculated from~\cite{StochasticTermination} supplementary data).
					\textbf{D.} Autocorrelation of simulated data of a population of 1000 cells, taking only one tenth of the genome per cell (100-fold coverage).
				}
		\end{figure}
		
		In addition to measuring the distribution of the point-by-point differences in experimental data, we measured the correlation length.
		Figure~\ref{fig:correlation}C shows the autocorrelation of the differences after the mean difference had been subtracted.
		We observe two features in the autocorrelation function.
		There is a delta function at $\Delta x=0$, implying that the noise between neighbouring data points is large.
		However, there is also a non-negligible tail, implying long-range order in the experimental data.
		
		
		\subsection{Estimating Simulation Noise}
		\label{subsec:SimulationNoise}
		
		Now that we have estimated noise level in current sequencing experiments, we would like to use those data to ensure our simulated replicated fraction has noise commensurate with experimental data.
		Two steps were taken to make this happen: the first based on experimental procedures, the second by artificially adding Gaussian noise.
		
		The first step taken to make our simulated data similar to experimental data was to limit the size of the population of simulated cells.
		As we mentioned above, the Monte Carlo program operates by taking the average of many cells, which is very similar to sequencing experimental techniques.
		In their experiment, Hawkins~\emph{et al.} extracted 10--25 million 50 bp sequences~\cite{StochasticTermination}.
		Over the genome of 12 Mb, that is equivalent to 50-to 100-fold coverage per base.
		Therefore, we limited our simulations to a population of 100 cells to get equivalent coverage.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=\textwidth]{Images/SimNoise.pdf}
			\end{center}
				\caption[Estimating Simulation Noise: Point-By-Point Difference Distributions]{\label{fig:SimNoise} Histograms of the point-by-point difference between two sets of simulated data.
					Each set of axis is for a different time after the start of S phase (labeled).
					y-axis shows the normalized distribution.
					x-axis shows difference.
					Grey circles are calculated from experiment.
					Black line at $t=15$ shows the best Laplace distribution fit.
					Black line at $t=30$ shows the best Gaussian fit.
				}
		\end{figure}
		
		We generated two simulated replicated fraction functions over the entire genome from 100-cell populations (parameters were set using results from the MIM~\cite{ScottsPaper}).
		These two functions were used to estimate the noise in the simulation, $\sigma_\text{sim}$, using the same process as outlined in Sec.~\ref{subsec:SequencingNoise}.
		Figure~\ref{fig:SimNoise} shows the distributions of the difference at each time step.
		Interestingly, there is an evolution in the noise from near-Laplace distributed at early time, to near Gaussian, and back to near-Laplace distributed.
		Figure~\ref{fig:Noise} shows our estimation of the noise in simulation, measured using built-in IGOR Pro tools that report the standard deviation of a set of data.
		
		Is  noise in simulations distributed differently than the noise in experiment?
		To address this concern, we qualitatively investigated a possible source of the noise.
		We know that the greatest uncertainty in replicated fraction will coincide with the presence of forks of replication:
		While regions that replicate early and regions that replicate late will simulate a replicated fraction of primarily ones and primarily zero respectively, regions that are in the process of replicating will return both values.
		Therefore, we measured  the average number of replicated regions across the genome over simulation time (Fig.~\ref{fig:NumberIslands}).
		Except when a fork has hit the end of the chromosome, the number of forks is twice the number of replicated regions.
		We observed a peak in the number of replicated regions, and hence forks, at 30 minutes after the start of S phase.
		This time coincides with the time at which the distribution of the simulated noise is most Gaussian (Fig.~\ref{fig:SimNoise}).
		Thus, noise in simulation is Laplace distributed when the number of forks is small, and adding more forks makes the distribution more Gaussian.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=.8\textwidth]{Images/NumIslands.pdf}
			\end{center}
			\caption[Number of Replicated Regions in Simulation]{\label{fig:NumberIslands}
				Histogram of the number of replicated regions per cell in the simulation.
				x-axis shows $t_\text{sim}$ in minutes.
			}
		\end{figure}
		
		
		\subsection{Adding Gaussian Noise to the MIM Simulator}
		\label{subsec:AddingNoise}
		
		We changed two features of the noise in simulation to better produce noise commensurate with experiments.
		First, as shown in Fig.~\ref{fig:Noise}, the statistical noise that arises from the random sampling of the Monte Carlo process is not large enough to match the noise we estimated for the experiment.
		Second, as shown in Fig.~\ref{fig:correlation}A and C, the experimental data has a short-range disorder that is lacking in the simulation over a population of 100 cells.
		Therefore, we added extra noise to the simulated data to match the levels we found in Sec.~\ref{subsec:SequencingNoise}.
		To add the noise, we used our estimate of the uncertainty from the simulation, $\sigma_\text{sim}$, then calculated the amount of Gaussian noise we had to add, $\sigma_\text{add}$, such that the resulting uncertainty matched the desired values:
		\begin{equation} \label{eq:AddingNoise}
			\sigma_\text{add} = \sqrt{{\sigma_t}^2 - {\sigma_\text{sim}}^2} \text{ ,}
		\end{equation}
		where $\sigma_t$ is the experimental noise calculated for the simulated time $t$ from experimental data (Sec.~\ref{subsec:SequencingNoise}).
		The crosses in Fig.~\ref{fig:Noise} show the resulting values of $\sigma_\text{add}$ that were used for our simulations.
		
		\begin{figure}[tbh]
			\begin{center}
				\includegraphics[width=\textwidth]{Images/NoisySimNoise.pdf}
			\end{center}
				\caption[Simulation Point-By-Point Difference Distributions With Artificial Noise]{\label{fig:NoisySimNoise} Histograms of the point-by-point difference between two sets of simulated data with artificially added Gaussian noise.
					Each set of axis is for a different time after the start of S phase (labeled).
					y-axis shows the normalized distribution.
					x-axis shows difference.
					Grey circles are calculated from experiment.
					Black lines show the best Gaussian distribution fit.
				}
		\end{figure}
		
		Figure~\ref{fig:correlation}B shows the autocorrelation function for the simulated data with artificial noise.
		With the addition of the noise, we have acquired the delta function at $x=0$ but lost much of the long-range order.
		To understand the effect that creates the long-range order in experiment, and potentially improve our simulation, we tried a second approach to creating noise.
		This new approach, called the ``sequencing simulation,'' simulates 1000 cells, records only one tenth of the data, and does not add any artificial noise.
		With this method, the simulation is closer to sequencing experiments which pull 50 kb sequences from an effectively infinite population.
		Analysis of the point-by-point difference shows a similar evolution from Laplace distributed noise to Gaussian (figure not shown).
		The estimated standard deviations, shown as black squares in Fig.~\ref{fig:Noise}, are closer to the experimental estimates than our initial simulation but do not coincide.
		However, as shown in Fig.~\ref{fig:correlation}D, the correlation length is shorter in this case than in the simulation with added noise.
		
		In the end, we chose to artificially add noise to a simulation of 100 cells.
		Adding artificial noise has three main benefits:
		First, it effectively increases the uncertainty in the simulated data to match that seen experimentally.
		Second, the artificial noise pushes the differences between simulations closer to the Gaussian distribution we observe in experimental data.
		Third, it is about 10 times faster than simulating 1000 cells and taking one tenth of the data.
		Figure~\ref{fig:SimulatedExample} shows a comparison of simulated data before and after noise has been added artificially.
		Figure~\ref{fig:NoisySimNoise} shows the distribution of noise, measured as outlined in Sec.~\ref{subsec:SequencingNoise}.
		These distributions are a much better match to those shown in Fig.~\ref{fig:HistDifference} with the addition of Gaussian noise.
		The estimated standard deviations from the simulations with artificial noise (shown as dots in Fig.~\ref{fig:Noise}) are within one percent of those estimated from experimental data.
		
		To better include noise in simulations, the two features discussed above need to be addressed.
		We believe a better understanding of the experimental procedure and its sources of error would help with both of these.
		Given that the analysis above shows adding Gaussian noise makes the simulation noise match experimental noise much more closely, we believe the presented method is an effective first approach to incorporating noise in the MIM simulator.









































